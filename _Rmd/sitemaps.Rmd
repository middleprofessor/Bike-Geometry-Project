---
title: "sitemap generator"
author: "Jeffrey Walker"
date: "`r Sys.Date()`"
output: html_document
---

```{r}

# Je charge dans une variable la liste des librairies que je vais utiliser
packages <- c("Rcrawler","dplyr", "stringr","xml2","tidyverse","tidyr")
 
# fonction permettant d'installer automatiquement les librairies n?cessaires & non install?es
if (length(setdiff(packages, rownames(installed.packages()))) > 0) {
  install.packages(setdiff(packages, rownames(installed.packages())))  
}
library(Rcrawler)
library(dplyr)
library(stringr)
library(xml2)
library(tidyverse)
library(tidyr)
library(here) # my addition

outfile <- here("docs/sitemap.xml") # my addition


#1 - I SET UP MY CRAWL
CustomLabels <- c("canonical_tag", "meta_robots")
 
CustomXPaths <- c("//link[@rel='canonical']/@href", "//meta[@name='robots']/@content")
 
#2 - WE START CRAWLING 
Rcrawler(Website = "https://bikegeometry.site", 
         ExtractXpathPat = CustomXPaths, 
         PatternsNames = CustomLabels)
 
#3 - WE MERGE DATA
crawl <-data.frame(do.call("rbind", DATA))
crawl_complete <- cbind(INDEX,crawl)
Idurl = as.numeric(crawl_complete$Id)
crawl_complete = cbind(Idurl,crawl_complete)
        
#2 - I IDENTIFY INDEXABLE PAGES
crawl_complete <- mutate(crawl_complete, Canonical_indexability = ifelse(Url == canonical_tag | is.na(crawl_complete$canonical_tag), "Canonical Matching", "Canonical not Matching")) 
crawl_complete <- mutate(crawl_complete, indexation = ifelse(grepl("NOINDEX|noindex", crawl_complete$meta_robots), "Non Indexable", "Indexable")) 
 
#3 - I KEEP ONLY INDEXABLE PAGES
crawl_complete_indexable_pages <- filter(crawl_complete, indexation =="Indexable" & Canonical_indexability == "Canonical Matching" )
 
#4 - I KEEP ONLY URLS
column_to_keep_sc <- c("Url")
crawl_complete_indexable_pages = INDEX[column_to_keep_sc]
 
 
#5 - I SPLIT BY PAGE TYPE (NOT NECESSARY)
crawl <- mutate(crawl_complete_indexable_pages, category = ifelse(str_detect(crawl_complete_indexable_pages$Url,"/blog/"), "Articles",
                                         ifelse(str_detect(crawl_complete_indexable_pages$Url, "/learn/"), "Learn pages",
                                                ifelse(str_detect(crawl_complete_indexable_pages$Url, "Products"),"Products", "Community"))))
#6 - I CREATE SEVERAL FILES 
sitemap_1 <- filter(crawl, category =="Community")
column_to_keep_sc <- c("Url")
sitemap_articles = sitemap_1[column_to_keep_sc]
 
# sitemap_2 <- filter(crawl, category =="Learn pages")
# column_to_keep_sc <- c("Url")
# sitemap_learn = sitemap_2[column_to_keep_sc]
#  
# sitemap_3 <- filter(crawl, category =="Products")
# column_to_keep_sc <- c("Url")
# sitemap_products = sitemap_3[column_to_keep_sc]
#  
 
 
#4 - FROM THESE FILES, I CREATE SITEMAPS 
require(whisker)
require(httr)
tpl <- '
<?xml version="1.0" encoding="UTF-8"?>
<urlset xmlns="http://www.sitemaps.org/schemas/sitemap/0.9">
 {{#links}}
   <url>
      <loc>{{{loc}}}</loc>
      <lastmod>{{{lastmod}}}</lastmod>
      <changefreq>{{{changefreq}}}</changefreq>
      <priority>{{{priority}}}</priority>
   </url>
 {{/links}}
</urlset>
'
links = as.character(sitemap_articles$Url)
 
 
map_links <- function(l) {
  tmp <- GET(l)
  d <- tmp$headers[['last-modified']]
   
  list(loc=l,
       #lastmod=format(as.Date(d,format="%Y.%m.%d")),
       lastmod=format(Sys.time(), "%Y-%m-%d"),
       changefreq="monthly",
       priority="0.8")
}
 
print(map_links)
links <- lapply(links, map_links)
print(links)
cat(whisker.render(tpl),file = outfile)
```

